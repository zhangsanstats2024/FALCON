{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "import L0_card\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "batch_size = 16\n",
    "seed = 0\n",
    "model_name = \"mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started logging run 20220720_13-56-05_433106_64 of experiment mlpnet, saving checkpoints every 1 epoch\n",
      "this is config before OrderedDict([('pruners', OrderedDict([('pruner_1', OrderedDict([('class', 'WoodburryFisherPruner'), ('epochs', [0, 2, 2]), ('weight_only', True), ('initial_sparsity', 0.0), ('target_sparsity', 0.9), ('modules', ['fc2']), ('keep_pruned', True)]))])), ('trainers', OrderedDict([('default_trainer', OrderedDict([('optimizer', OrderedDict([('class', 'SGD'), ('lr', 0.001), ('momentum', 0.5)])), ('lr_scheduler', OrderedDict([('class', 'ExponentialLR'), ('gamma', 0.9), ('epochs', [120, 1, 140])]))]))]))])\n",
      "Overwrite arguments for one-shot!\n",
      "this is config after OrderedDict([('pruners', OrderedDict([('pruner_1', OrderedDict([('class', 'BlockwiseWoodburryFisherPruner'), ('epochs', [0, 1, 1]), ('weight_only', True), ('initial_sparsity', 0.9), ('target_sparsity', 0.9), ('modules', ['fc1', 'fc2', 'fc3']), ('keep_pruned', True)]))])), ('trainers', OrderedDict([('default_trainer', OrderedDict([('optimizer', OrderedDict([('class', 'SGD'), ('lr', 0.001), ('momentum', 0.5)])), ('lr_scheduler', OrderedDict([('class', 'ExponentialLR'), ('gamma', 0.9), ('epochs', [120, 1, 140])]))]))]))])\n",
      "total epochs is 1\n",
      "True, not_oldfashioned\n",
      "/home/mengx/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:122: UserWarning: \n",
      "    Found GPU0 Tesla K20m which is of cuda capability 3.5.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is 3.7.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, minor, min_arch // 10, min_arch % 10))\n",
      "Module .fc1 was successfully wrapped\n",
      "Module .fc2 was successfully wrapped\n",
      "Module .fc3 was successfully wrapped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also printing results@top5 as well!\n",
      "Do log softmax:  True\n",
      "=======Layers:=============\n",
      "====================\n",
      "current_model_config {'arch': 'mlpnet', 'dataset': 'mnist', 'use_butterfly': False}\n",
      "Do log softmax:  True\n",
      "updated_state_dict odict_keys(['fc1._weight_mask', 'fc1._layer.weight', 'fc2._weight_mask', 'fc2._layer.weight', 'fc3._weight_mask', 'fc3._layer.weight'])\n",
      "args is  Namespace(aa=False, always_eval_test=False, arch='mlpnet', aux_gpu_id=-1, batch_size=64, batched_test=False, cache_subset_ids=False, centered=False, check_grads=False, check_train_loss=False, checkpoint_freq=1, ckpt_epoch=-1, compare_globalmagni_mask=False, compare_models=False, config_path='../WoodFisher/configs/mlpnet_mnist_config_one_shot_woodburry_fisher.yaml', cpu=True, deterministic=True, device=device(type='cpu'), disable_bias=True, disable_log_soft=False, disable_train_random_transforms=False, disable_train_shuffle=False, disable_wdecay_after_prune=False, dset='mnist', dset_path='./datasets', dump_fisher_inv_mat=False, dump_grads_mat=False, enable_dropout=False, epochs=1, eps=1e-10, eval_fast=False, exp_dir='../exp_root/mlpnet', exp_name='mlpnet', experiment_root_path='../exp_root', export_onnx=False, fisher_cpu=False, fisher_damp=1e-05, fisher_damp_correction=False, fisher_effective_damp=False, fisher_mini_bsz=1, fisher_optimized=False, fisher_parts=5, fisher_seed=-1, fisher_split_grads=False, fisher_subsample_size=100, fisher_trace=False, fittable_params=-1, flops=False, flops_epsilon=1, flops_normalize=None, flops_per_param=False, flops_power=0, flops_target=-1, from_checkpoint_path='../WoodFisher/checkpoints/mnist_25_epoch_93.97.ckpt', full_subsample=True, gpus=-1, grad_subsample_size=None, hess_label_smoothing=None, ignore_prefix=False, init_sparsity=0.9, inspect_inv=False, kernel_sizes=3, kfac_pi=False, label_smoothing=0, layer_trace_stat=False, load_distiller_weights_from=None, load_fisher='', local_quadratic=False, logging_level=10, mask_onnx=False, max_mini_bsz=None, no_dataparallel=False, normalize_hgp=False, normalize_update=False, normalize_update_mult=1, not_oldfashioned=True, num_classes=10, num_hidden_nodes1=40, num_hidden_nodes2=20, num_path_steps=-1, num_samples=100, offload_grads=False, offload_inv=False, old_fashioned=False, one_shot=True, onnx_nick=None, p=3, pretrained=False, previous_mask=False, prune_all=False, prune_at_launch=False, prune_bias=False, prune_class='woodfisherblock', prune_direction=False, prune_end=1, prune_freq=1, prune_lr=None, prune_modules='fc1_fc2_fc3', prune_momentum=None, prune_optimizer=None, prune_start=0, prune_wdecay=0, recompute_bn_stats=False, recompute_degree=None, recompute_num=None, recompute_schedule=None, repeated_one_shot=False, report_top5=True, reset_training_policy=False, result_file='./tests/results_1658339765.csv', run_dir='../exp_root/mlpnet/20220720_13-56-05_433106_64', run_id='20220720_13-56-05_433106_64', save_before_prune_ckpt=False, save_dense_also=False, save_fisher=False, scale_prune_update=1, se_ratio=None, seed=1, set_prune_momentum=False, spearman_globalmagni=False, subtract_min=False, sweep_id=64, target_sparsity=0.9, test_batch_size=None, topk=False, training_stats_freq=30, true_fisher=False, untrained_last=False, update_config=True, use_butterfly=False, use_model_config=True, use_se=False, woodburry_joint_sparsify=True, woodtaylor_abs=False, workers=1, zero_after_prune=False)\n",
      "Copy param module.fc1._weight_mask with shape torch.Size([40, 784]) in checkpoint to fc1._weight_mask\n",
      "Copy param module.fc1._layer.weight with shape torch.Size([40, 784]) in checkpoint to fc1._layer.weight\n",
      "Copy param module.fc2._weight_mask with shape torch.Size([20, 40]) in checkpoint to fc2._weight_mask\n",
      "Copy param module.fc2._layer.weight with shape torch.Size([20, 40]) in checkpoint to fc2._layer.weight\n",
      "Copy param module.fc3._weight_mask with shape torch.Size([10, 20]) in checkpoint to fc3._weight_mask\n",
      "Copy param module.fc3._layer.weight with shape torch.Size([10, 20]) in checkpoint to fc3._layer.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructed BlockwiseWoodburryFisherPruner with config:\n",
      "    -epochs:[0, 1, 1]\n",
      "    -weight_only:True\n",
      "    -initial_sparsity:0.9\n",
      "    -target_sparsity:0.9\n",
      "    -modules:['fc1', 'fc2', 'fc3']\n",
      "    -keep_pruned:True\n",
      "\n",
      "IN BLOCK WOODBURRY\n",
      "initial sparsity in args is 0.9\n",
      "initial sparsity in config is 0.9\n",
      "../WoodFisher/models/mlpnet.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---computing gradients--  0\n",
      "---computing gradients--  100\n",
      "---computing gradients--  200\n",
      "---computing gradients--  300\n",
      "---computing gradients--  400\n",
      "---computing gradients--  500\n",
      "---computing gradients--  600\n",
      "---computing gradients--  700\n",
      "---computing gradients--  800\n",
      "---computing gradients--  900\n"
     ]
    }
   ],
   "source": [
    "X, w_bar, model, train_dataloader, test_dataloader, modules_to_prune = load_Xw(model_name, sample_size, batch_size, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntar is  3235\n",
      "Shape of X is  (1000, 32360)\n"
     ]
    }
   ],
   "source": [
    "y = X@w_bar\n",
    "p = w_bar.shape[0]\n",
    "beta = w_bar\n",
    "r = y - X@beta\n",
    "sparsity = 0.9\n",
    "ntot = w_bar.shape[0]\n",
    "ntar = int(ntot * (1-sparsity))\n",
    "print(\"ntar is \",ntar)\n",
    "print(\"Shape of X is \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparsity list\n",
    "k_list = [0.2,0.4,0.6,0.8,0.9,0.95,0.98]\n",
    "\n",
    "# complexity is O(iter * non-zeros)\n",
    "iter_list = [10,20,30,50,75,100,300]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj is 0.029101356518172625 cur sparsity is 0.2 Sol time is 1.3076162338256836\n",
      "obj is 0.12107871550036534 cur sparsity is 0.4 Sol time is 1.4206759929656982\n",
      "obj is 0.2884015475185811 cur sparsity is 0.6 Sol time is 1.264383316040039\n",
      "obj is 0.5608207628983639 cur sparsity is 0.8 Sol time is 0.9449284076690674\n",
      "obj is 0.7752349944546097 cur sparsity is 0.9 Sol time is 0.6572799682617188\n",
      "obj is 0.949642508264156 cur sparsity is 0.95 Sol time is 0.40872788429260254\n",
      "obj is 1.1201028181324248 cur sparsity is 0.98 Sol time is 0.5852174758911133\n"
     ]
    }
   ],
   "source": [
    "# initial soluition\n",
    "beta = np.copy(w_bar)\n",
    "n, p = X.shape\n",
    "for i in range(len(k_list)):\n",
    "    k = int(p*(1-k_list[i]))\n",
    "    cd_max_itr = iter_list[i]\n",
    "    \n",
    "    # active set size is max(k, min(p,kimp*k,buget)), here you can fix kimp=1, buget=inf\n",
    "    beta, f, r, sol_time = L0_card.Heuristic_CD(y,X,beta,k,alpha=np.zeros(p),lambda1=0.001,\n",
    "        lambda2=0.01, beta_tilde1=np.copy(w_bar), beta_tilde2=np.copy(w_bar), M=np.inf,\n",
    "                        cd_max_itr=cd_max_itr,buget=None,kimp=1,sto_m = \"sto\")\n",
    "    \n",
    "    # update X, y and w_bar based on current solution beta here\n",
    "    pass\n",
    "    \n",
    "    print(\"obj is\",f,\"cur sparsity is\",k_list[i],\"Sol time is\",sol_time)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
